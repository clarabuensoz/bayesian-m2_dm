---
title: "ProjetBayésien"
author: "orianebasso"
date: "2022-12-22"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Article: Upper respiratory tract disease, force of infection, and
effects on survival of gopher tortoises

## Libraries

```{r}
library(ggplot2)
library(dplyr)
library(R2jags)
```

## Part 1: Lecture, exploration des données

Lisez les données, et assurez vous que les variables sont au bon format.
Calculez des statistiques descriptives des données, et proposez des
visualisations graphiques. Commentez ce que vous retenez de
l'exploration des données.

### Mise en forme des données

```{r}

#setwd("C:/Users/clarr/Documents/GitHub/bayesian-m2_dm")
setwd("C:/Users/orian/OneDrive/Documents/bayesian-m2_dm")
data<-read.csv2("gopher.csv")
str(data)
data$prev<-as.numeric(data$prev)
data$Area<-as.numeric(data$Area)
data$year<-as.numeric(data$year)
data$density<-as.numeric(data$density)
data$taillepop<-data$density*data$Area
taillepop<-data$taillepop
names(data)[1]<-"Site"

```

Comme les auteurs le font remarquer dans leur article, les données sont
peu nombreuses.

```{r eval=FALSE}
#plot(density(data$prev))

#plot(data$prev,data$shell)
#plot(data$prev,data$density)

ggplot(data, aes(x=Site, y=shells/taillepop, fill=Site)) + 
  geom_boxplot(show.legend = F)+
  labs(title="Figure 1 : Shells per individual at each site", 
       x="Sites",
       y="Shell per individual")+
  theme_bw()
```

```{r}
ggplot(data, aes(x=Site, y=prev, fill=Site)) + 
  geom_boxplot(show.legend = F)+
  labs(title="Figure 2 : Mycoplasma agassizii seroprevalence at each site", 
       x="Sites",
       y="Seroprevalence")+
  theme_bw()

ggplot(data, aes(x=Site, y=shells/taillepop, fill=Site)) + 
  geom_boxplot(show.legend = F)+
  labs(title="Figure 1 : Shells per individual at each site", 
       x="Sites",
       y="Shell per individual")+
  theme_bw()

ggplot(data, aes(x=prev, y=shells/taillepop, color=year)) + 
  geom_point(show.legend = T, size=6)+
   labs(title="Figure 3 : Shell remains per individual for each year of the study along Mycoplasma agassizii seroprevalence", 
       x="Seroprevalence",
       y="Shell per individual")+
  theme_bw()

ggplot(data, aes(x=prev, y=shells/taillepop, color=Site)) + 
  geom_point(show.legend = T, size=6)+
   labs(title="Figure 3 : Shell remains per individual for each year of the study along Mycoplasma agassizii seroprevalence", 
       x="Seroprevalence",
       y="Shell per individual")+
  theme_bw()



# Verification pour offset (ne pas inclure)
ggplot(data, aes(x=prev, y=log(A), color=Site)) + 
  geom_point(show.legend = T, size=6)+
   labs(title="Figure 4 : Seroprevalence against log(Area)", 
       x="Seroprevalence",
       y="log(A)")+
  theme_bw()
ggplot(data, aes(x=log(prev), y=log(A), color=Site)) + 
  geom_point(show.legend = T, size=6)+
   labs(title="Figure 4 : Seroprevalence against log(Area)", 
       x="Seroprevalence",
       y="A")+
  theme_bw()
  

```

```{r}
summary(data)

#ggplot(data, aes(shells, color = Site,fill=taillepop)) + geom_histogram(binwidth = 1) 
```

## Part 2 : Models implementation

### Data

```{r}
# Define numeric vector for the factor Site
Site<-as.numeric(data$Site)
# Define response variable : shell remains count
y<-data$shells
# Standardize explanatory variables
x<-(data$prev - mean(data$prev))/sd(data$prev)

#mean(x)
#sd(x)
#hist(x)

```

### Model 1

Y\~ Poisson (T \* u) log (u) = a0 Prior: a0\~ N(0,sd=10)

Avec : - Y = nombre de carapaces - T = taille de la population - a0 =
intercept =

```{r}
#Create dataframe of data for this model:
mydata<-list(y=y,n=length(y),N=taillepop)
```

#### Write the model:

```{r}
model_1<-function(){
  # likelihood
  for(i in 1:n){
    y[i] ~ dpois(lambda[i]) #likelihood
    lambda[i]<-N[i]*u[i]
    log(u[i]) <- a0
  }
  # priors
  a0 ~ dnorm(0,0.1) # sd=10
}
```

#### Specify info to Jags

Initial values: We specify the initial values for 3 markov chains:

```{r}
init1 <- list(a0 = -4)
init2 <- list(a0 = -3)
init3 <- list(a0 = -2)
init <- list(init1,init2,init3)
```

Parameters to monitor :

```{r}
params <- c("a0")
```

#### Fit the model with Jags

```{r}
model1_fit <- jags(data = mydata,
                             inits = init,
                             parameters.to.save = params,
                             model.file = model_1,
                             n.chains = 3,
                             n.iter = 6000,
                             n.burnin = 3000,
                             n.thin = 1)
```

```{r}
model1_fit
```

#### Assess convergence

##### Qualitativement par des graphiques:

```{r}
traceplot(model1_fit,mfrow=c(1,2),varname=c("a0"),ask=FALSE)
```

Selon ce graphique, les 3 chaines mixent bien.
Le choix du nombre de burnin semble être assez long pour discard les samples pris avant d'atteindre la distribution stationnaire postérieure. 

autocorr.plot(as.mcmc(model1_fit),ask=FALSE)
On observe une autocorrelation limitée, le nombre d'itérations spécifié semble convenir.

##### Quantitativement:
###### N.eff : nb itérations ok pour limiter effet autocorrelation chaine
The effective sample size n.eff mesure la longueur de la chaine nécessaire en prenant en compte la corrélation entres celle ci. 
Le critère généralement choisit est de n.eff >100.
Ici on a bien nf >100. Donc le nombre d'itération est suffisant pour obtenir des estimateurs représentatif de la distribution postérieure.
```{r}
model1_fit
```

###### Rhat: détecte si problème de convergence

Rhat mesure le ratio de la variabilité totale combinant multiple chaine
(entre les chaines et au sein des chaines) à la variabilité intra
chaine. Condition nécessaire pour atteindre la convergence: Rhat \<1.1.
Mais attention, cela nous indique uniquement si la chaine n'a pas
convergé. On ne peut pas être certain de la convergence même si le
critère est \<1.1.

-\> Valeur proche 1 : indique convergence probable. Acceptable si
inférieur à 1.1 Ici on a une valeur proche de 1. Rien à signaler
d'anormal pour la convergence.

#### Model selection: Compute WAIC criterion

```{r}
samples <- jags.samples(model1_fit$model,c("WAIC","deviance"), type = "mean",
n.iter = 6000,
n.burnin = 3000,
n.thin = 1)
samples$p_waic <- samples$WAIC #number of parameters
# Calculate the true AIC:
samples$waic <- samples$deviance + samples$p_waic
tmp <- sapply(samples, sum)
waic <- round(c(waic = tmp[["waic"]], p_waic = tmp[["p_waic"]],deviance = tmp[["deviance"]]),1)
waic$Modelname<-"model1"
waic$prior<-"a0~ N(0,sd=10)"

# Save the result:
waic_save<-as.data.frame(waic)
                     
```

#### The results: look to posterior distributions

```{r}
# have a look to posterior distribution
hist(model1_fit$BUGSoutput$sims.matrix[,"a0"])
plot(density(model1_fit$BUGSoutput$sims.matrix[,"a0"]))
```

### Model 1_bis

Y\~ Poisson (T \* u) log (u) = a0 + log (A) Prior: a0\~ N(0,sd=10)

```{r}
#Create dataframe of data for this model:
A<-as.numeric(data$Area)
mydata<-list(y=y,n=length(y),A=A,N=taillepop)
```

#### Write the model:

```{r}
model_1_bis<-function(){
  # likelihood
  for(i in 1:n){
    y[i] ~ dpois(lambda[i]) #likelihood
    lambda[i]<-N[i]*u[i]
    log(u[i]) <- a0 + log(A[i])
  }
  # priors
  a0 ~ dnorm(0,0.1) # sd=10
}
```

#### Specify info to Jags

Initial values: We specify the initial values for 3 markov chains:

```{r}
init1 <- list(a0 = -4)
init2 <- list(a0 = -3)
init3 <- list(a0 = -2)
init <- list(init1,init2,init3)
```

Parameters to monitor :

```{r}
params <- c("a0")
```

#### Fit the model with Jags

```{r}
model1_bis_fit <- jags(data = mydata,
                             inits = init,
                             parameters.to.save = params,
                             model.file = model_1_bis,
                             n.chains = 3,
                             n.iter = 6000,
                             n.burnin = 3000,
                             n.thin = 1)
```

```{r}
model1_bis_fit
```

#### Assess convergence

##### Qualitativement par des graphiques:

```{r}
traceplot(model1_bis_fit,mfrow=c(1,2),varname=c("a0"),ask=FALSE)
```
Selon ce graphique, les 3 chaines mixent bien.
Le choix du nombre de burnin semble être assez long pour discard les samples pris avant d'atteindre la distribution stationnaire postérieure. 

autocorr.plot(as.mcmc(model1_bis_fit),ask=FALSE)
On observe une autocorrelation limitée, le nombre d'itérations spécifié semble convenir.

##### Quantitativement:
###### N.eff : nb itérations ok pour limiter effet autocorrelation chaine
The effective sample size n.eff mesure la longueur de la chaine nécessaire en prenant en compte la corrélation entres celle ci. 
Le critère généralement choisit est de n.eff >100.
Ici on a bien nf >100. Donc le nombre d'itération est suffisant pour obtenir des estimateurs représentatif de la distribution postérieure.

```{r}
model1_bis_fit
```

###### Rhat: détecte si problème de convergence

Rhat mesure le ratio de la variabilité totale combinant multiple chaine
(entre les chaines et au sein des chaines) à la variabilité intra
chaine. Condition nécessaire pour atteindre la convergence: Rhat \<1.1.
Mais attention, cela nous indique uniquement si la chaine n'a pas
convergé. On ne peut pas être certain de la convergence même si le
critère est \<1.1.

-\> Valeur proche 1 : indique convergence probable. Acceptable si
inférieur à 1.1 Ici on a une valeur proche de 1. Rien à signaler
d'anormal pour la convergence.

#### Model selection: Compute WAIC criterion

```{r}
samples <- jags.samples(model1_bis_fit$model,c("WAIC","deviance"), type = "mean",
n.iter = 6000,
n.burnin = 3000,
n.thin = 1)
samples$p_waic <- samples$WAIC #number of parameters
# Calculate the true AIC:
samples$waic <- samples$deviance + samples$p_waic
tmp <- sapply(samples, sum)
waic <- round(c(waic = tmp[["waic"]], p_waic = tmp[["p_waic"]],deviance = tmp[["deviance"]]),1)
waic$Modelname<-"model1_bis"
waic$prior<-"a0~ N(0,sd=10)"
# Save the result:
waic<-as.data.frame(waic)
waic_save<-rbind(waic_save,waic)
                     
```

#### The results: look to posterior distributions

```{r}
# have a look to posterior distribution
hist(model1_fit$BUGSoutput$sims.matrix[,"a0"])
plot(density(model1_fit$BUGSoutput$sims.matrix[,"a0"]))
```

### Model 2

Y\~ Poisson (T \* u) log (u) = a0 + a1 P Prior: a0\~ N(0,sd=10) a1\~
N(0,sd=10)

```{r}
#Create dataframe of data for this model:
mydata<-list(y=y,x=x,n=length(y),N=taillepop)
```

#### Write the model:

```{r}
model_2<-function(){
  # likelihood
  for(i in 1:n){
    y[i] ~ dpois(lambda[i]) #likelihood
    lambda[i]<-N[i]*u[i]
    log(u[i]) <- a0 + a1*x[i]
  }
  # priors
  a0 ~ dnorm(0,0.1) # sd=10
  a1 ~ dnorm(0,0.1) 
}
```

#### Specify info to Jags

Initial values: We specify the initial values for 3 markov chains:

```{r}
init1 <- list(a0 = -4,a1=0)
init2 <- list(a0 = -3,a1=1)
init3 <- list(a0 = -2,a1=-1)
init <- list(init1,init2,init3)
```

Parameters to monitor :

```{r}
params <- c("a0","a1")
```

#### Fit the model with Jags

```{r}
model2_fit <- jags(data = mydata,
                             inits = init,
                             parameters.to.save = params,
                             model.file = model_2,
                             n.chains = 3,
                             n.iter = 6000,
                             n.burnin = 3000,
                             n.thin = 1)
```

```{r}
model2_fit
```

#### Assess convergence

##### Qualitativement par des graphiques:

```{r}
traceplot(model2_fit,mfrow=c(1,2),varname=c("a0","a1"),ask=FALSE)
```

Selon ce graphique, les 3 chaines mixent bien.
Le choix du nombre de burnin semble être assez long pour discard les samples pris avant d'atteindre la distribution stationnaire postérieure. 

autocorr.plot(as.mcmc(model2_fit),ask=FALSE)
On observe une autocorrelation limitée, le nombre d'itérations spécifié semble convenir.

##### Quantitativement:
###### N.eff : nb itérations ok pour limiter effet autocorrelation chaine
The effective sample size n.eff mesure la longueur de la chaine nécessaire en prenant en compte la corrélation entres celle ci. 
Le critère généralement choisit est de n.eff >100.
Ici on a bien nf >100. Donc le nombre d'itération est suffisant pour obtenir des estimateurs représentatif de la distribution postérieure.

```{r}
model2_fit
```

###### Rhat: détecte si problème de convergence

Rhat mesure le ratio de la variabilité totale combinant multiple chaine
(entre les chaines et au sein des chaines) à la variabilité intra
chaine. Condition nécessaire pour atteindre la convergence: Rhat \<1.1.
Mais attention, cela nous indique uniquement si la chaine n'a pas
convergé. On ne peut pas être certain de la convergence même si le
critère est \<1.1.

-\> Valeur proche 1 : indique convergence probable. Acceptable si
inférieur à 1.1 Ici on a une valeur proche de 1. Rien à signaler
d'anormal pour la convergence.

#### Model selection: Compute WAIC criterion

```{r}
samples <- jags.samples(model2_fit$model,c("WAIC","deviance"), type = "mean",
n.iter = 6000,
n.burnin = 3000,
n.thin = 1)
samples$p_waic <- samples$WAIC #number of parameters
# Calculate the true AIC:
samples$waic <- samples$deviance + samples$p_waic
tmp <- sapply(samples, sum)
waic <- round(c(waic = tmp[["waic"]], p_waic = tmp[["p_waic"]],deviance = tmp[["deviance"]]),1)
waic$Modelname<-"model2"
waic$prior<-"a0~ N(0,sd=10) / a1~ N(0,sd=10)"
# Save the result:
waic<-as.data.frame(waic)
waic_save<-rbind(waic_save,waic)
                     
```

#### The results: look to posterior distributions

```{r}
# have a look to posterior distribution
hist(model1_fit$BUGSoutput$sims.matrix[,"a0"])
plot(density(model1_fit$BUGSoutput$sims.matrix[,"a0"]))
```

### Model 2_bis - prior sd 10

Y\~ Poisson (T \* u) log (u) = a0 + a1 P + log(A) Prior: a0\~ N(0,sd=10)
a1\~ N(0,sd=10)

```{r}
#Create dataframe of data for this model:
A<-as.numeric(data$Area)
mydata<-list(y=y,x=x,n=length(y),N=taillepop,A=A)
```

#### Write the model:

```{r}
model_2_bis<-function(){
  # likelihood
  for(i in 1:n){
    y[i] ~ dpois(lambda[i]) #likelihood
    lambda[i]<-N[i]*u[i]
    log(u[i]) <- a0 + a1*x[i]+ log(A[i])
  }
  # priors
  a0 ~ dnorm(0,0.1) # sd=10
  a1 ~ dnorm(0,0.1) 
}
```

#### Specify info to Jags

Initial values: We specify the initial values for 3 markov chains:

```{r}
init1 <- list(a0 = -4,a1=0)
init2 <- list(a0 = -3,a1=1)
init3 <- list(a0 = -2,a1=-1)
init <- list(init1,init2,init3)
```

Parameters to monitor :

```{r}
params <- c("a0","a1")
```

#### Fit the model with Jags

```{r}
model2_bis_fit <- jags(data = mydata,
                             inits = init,
                             parameters.to.save = params,
                             model.file = model_2_bis,
                             n.chains = 3,
                             n.iter = 6000,
                             n.burnin = 3000,
                             n.thin = 1)
```

```{r}
model2_bis_fit
```

#### Assess convergence

##### Qualitativement par des graphiques:

```{r}
traceplot(model2_bis_fit,mfrow=c(1,2),varname=c("a0","a1"),ask=FALSE)
```
Selon ce graphique, les 3 chaines mixent bien.
Le choix du nombre de burnin semble être assez long pour discard les samples pris avant d'atteindre la distribution stationnaire postérieure. 

```{r}
autocorr.plot(as.mcmc(model2_bis_fit),ask=FALSE)
```
On observe une autocorrelation limitée, le nombre d'itérations spécifié semble convenir.

##### Quantitativement:
###### N.eff : nb itérations ok pour limiter effet autocorrelation chaine
The effective sample size n.eff mesure la longueur de la chaine nécessaire en prenant en compte la corrélation entres celle ci. 
Le critère généralement choisit est de n.eff >100.
Ici on a bien nf >100. Donc le nombre d'itération est suffisant pour obtenir des estimateurs représentatif de la distribution postérieure.

```{r}
model2_bis_fit
```

###### Rhat: détecte si problème de convergence

Rhat mesure le ratio de la variabilité totale combinant multiple chaine
(entre les chaines et au sein des chaines) à la variabilité intra
chaine. Condition nécessaire pour atteindre la convergence: Rhat \<1.1.
Mais attention, cela nous indique uniquement si la chaine n'a pas
convergé. On ne peut pas être certain de la convergence même si le
critère est \<1.1.

-\> Valeur proche 1 : indique convergence probable. Acceptable si
inférieur à 1.1 Ici on a une valeur proche de 1. Rien à signaler
d'anormal pour la convergence.

#### Model selection: Compute WAIC criterion

```{r}
samples <- jags.samples(model2_bis_fit$model,c("WAIC","deviance"), type = "mean",
n.iter = 6000,
n.burnin = 3000,
n.thin = 1)
samples$p_waic <- samples$WAIC #Close to number of parameters but not really
# Calculate the true AIC:
samples$waic <- samples$deviance + samples$p_waic
tmp <- sapply(samples, sum)
waic <- round(c(waic = tmp[["waic"]], p_waic = tmp[["p_waic"]],deviance = tmp[["deviance"]]),1)
waic$Modelname<-"model2_bis"
waic$prior<-"a0~ N(0,sd=10) / a1~ N(0,sd=10)"
# Save the result:
waic<-as.data.frame(waic)
waic_save<-rbind(waic_save,waic)
                     
```

#### The results: look to posterior distributions

```{r}
# have a look to posterior distribution
hist(model2_bis_fit$BUGSoutput$sims.matrix[,"a0"])
plot(density(model2_bis_fit$BUGSoutput$sims.matrix[,"a0"]))
```

### Model 2_bis - prior sd 1000

Y\~ Poisson (T \* u) log (u) = a0 + a1 P + log(A) Prior: a0\~
N(0,sd=1000) a1\~ N(0,sd=1000)

```{r}
#Create dataframe of data for this model:
A<-as.numeric(data$Area)
mydata<-list(y=y,x=x,n=length(y),N=taillepop,A=A)
```

#### Write the model:

```{r}
model_2_bis_bis<-function(){
  # likelihood
  for(i in 1:n){
    y[i] ~ dpois(lambda[i]) #likelihood
    lambda[i]<-N[i]*u[i]
    log(u[i]) <- a0 + a1*x[i]+ log(A[i])
  }
  # priors
  a0 ~ dnorm(0,0.001) # sd=10
  a1 ~ dnorm(0,0.001) 
}
```

#### Specify info to Jags

Initial values: We specify the initial values for 3 markov chains:

```{r}
init1 <- list(a0 = -4,a1=0)
init2 <- list(a0 = -3,a1=1)
init3 <- list(a0 = -2,a1=-1)
init <- list(init1,init2,init3)
```

Parameters to monitor :

```{r}
params <- c("a0","a1")
```

#### Fit the model with Jags

```{r}
model2_bis_bis_fit <- jags(data = mydata,
                             inits = init,
                             parameters.to.save = params,
                             model.file = model_2_bis_bis,
                             n.chains = 3,
                             n.iter = 6000,
                             n.burnin = 3000,
                             n.thin = 1)
```

```{r}
model2_bis_bis_fit
```

#### Assess convergence

##### Qualitativement par des graphiques:

```{r}
traceplot(model2_bis_fit,mfrow=c(1,2),varname=c("a0","a1"),ask=FALSE)
```
Selon ce graphique, les 3 chaines mixent bien.
Le choix du nombre de burnin semble être assez long pour discard les samples pris avant d'atteindre la distribution stationnaire postérieure. 

```{r}
autocorr.plot(as.mcmc(model2_bis_fit),ask=FALSE)
```
On observe une autocorrelation limitée, le nombre d'itérations spécifié semble convenir.

##### Quantitativement:
###### N.eff : nb itérations ok pour limiter effet autocorrelation chaine
The effective sample size n.eff mesure la longueur de la chaine nécessaire en prenant en compte la corrélation entres celle ci. 
Le critère généralement choisit est de n.eff >100.
Ici on a bien nf >100. Donc le nombre d'itération est suffisant pour obtenir des estimateurs représentatif de la distribution postérieure.

```{r}
model2_bis_bis_fit
```

###### Rhat: détecte si problème de convergence

Rhat mesure le ratio de la variabilité totale combinant multiple chaine
(entre les chaines et au sein des chaines) à la variabilité intra
chaine. Condition nécessaire pour atteindre la convergence: Rhat \<1.1.
Mais attention, cela nous indique uniquement si la chaine n'a pas
convergé. On ne peut pas être certain de la convergence même si le
critère est \<1.1.

-\> Valeur proche 1 : indique convergence probable. Acceptable si
inférieur à 1.1 Ici on a une valeur proche de 1. Rien à signaler
d'anormal pour la convergence.

#### Model selection: Compute WAIC criterion

```{r}
samples <- jags.samples(model2_bis_bis_fit$model,c("WAIC","deviance"), type = "mean",
n.iter = 6000,
n.burnin = 3000,
n.thin = 1)
samples$p_waic <- samples$WAIC #Close to number of parameters but not really
# Calculate the true AIC:
samples$waic <- samples$deviance + samples$p_waic
tmp <- sapply(samples, sum)
waic <- round(c(waic = tmp[["waic"]], p_waic = tmp[["p_waic"]],deviance = tmp[["deviance"]]),1)
waic$Modelname<-"model2_bis_bis"
waic$prior<-"a0~ N(0,sd=1000) / a1~ N(0,sd=1000)"
# Save the result:
waic<-as.data.frame(waic)
waic_save<-rbind(waic_save,waic)
                     
```

#### The results: look to posterior distributions

```{r}
# have a look to posterior distribution
hist(model2_bis_fit$BUGSoutput$sims.matrix[,"a0"])
plot(density(model2_bis_fit$BUGSoutput$sims.matrix[,"a0"]))
```

### Model 3

Y\~ Poisson (T \* u) log (u) = a0 + Es Prior: a0\~ N(0,sd=10) Es\~
N(mu.es,tau.es) #tau.es = 1/variance=sigma.es² mu.es\~N(0,sd=10) tau.es
\<- 1 / (sigma.es \* sigma.es) sigma.es\~Unif(0,100)

```{r}
#Create dataframe of data for this model:
A<-as.numeric(data$Area)
nbsites<-length(unique(data$Site))
sites<-as.numeric(as.factor(data$Site))
mydata<-list(y=y,n=length(y),N=taillepop,nbsites=nbsites,sites=sites)
```

#### Write the model:

```{r}
model_3<-function(){
  # likelihood
  for(i in 1:n){
    y[i] ~ dpois(lambda[i]) #likelihood
    lambda[i]<-N[i]*u[i]
    log(u[i]) <- a[sites[i]]  # + a1*x[i]
  }
  for(j in 1:nbsites){
    a[j] ~ dnorm(mu.a,tau.a)
  } # For random effect of site
  # priors
  #a ~ dnorm(0,0.1) # sd=10
  #a1 ~ dnorm(0,0.1)
  mu.a ~ dnorm(0,0.1)
  tau.a <- 1 / (sigma.a * sigma.a)
  sigma.a ~ dunif(0,100)
}
```

#### Specify info to Jags

Initial values: We specify the initial values for 3 markov chains:

```{r}
init1 <- list(mu.a=-3,sigma.a=0.5)
init2 <- list(mu.a=-1,sigma.a=1.5)
init3 <- list(mu.a=-2,sigma.a=1)
init <- list(init1,init2,init3)
```

Parameters to monitor :

```{r}
params <- c("mu.a","sigma.a")
```

#### Fit the model with Jags

```{r}
model3_fit <- jags(data = mydata,
                             inits = init,
                             parameters.to.save = params,
                             model.file = model_3,
                             n.chains = 3,
                             n.iter = 6000,
                             n.burnin = 3000,
                             n.thin = 1)
```

```{r}
model3_fit
```

#### Assess convergence

##### Qualitativement par des graphiques:

```{r}
traceplot(model3_fit,mfrow=c(1,2),varname=c("mu.a","sigma.a"),ask=FALSE)
```

Le mixage semble ok mais pas parfait.
```{r}
autocorr.plot(as.mcmc(model3_fit),ask=FALSE)
```
Avec les valeurs :n.iter = 6000, n.burnin = 3000, j'observe pas mal d'autocorrelationo pour sigma. Je décide d'augmenter le nombre d'itération à 8000. J'observe même résultat.  Changer  les valeurs initiales de modifie pas non plus.

Cependant, on observe une autocorrelation limitée, le nombre d'itérations spécifié semble convenir.

##### Quantitativement:
###### N.eff : nb itérations ok pour limiter effet autocorrelation chaine
The effective sample size n.eff mesure la longueur de la chaine nécessaire en prenant en compte la corrélation entres celle ci. 
Le critère généralement choisit est de n.eff >100.
Ici on a bien nf >100. Donc le nombre d'itération est suffisant pour obtenir des estimateurs représentatif de la distribution postérieure.

```{r}
model3_fit
```

###### Rhat: détecte si problème de convergence

Rhat mesure le ratio de la variabilité totale combinant multiple chaine
(entre les chaines et au sein des chaines) à la variabilité intra
chaine. Condition nécessaire pour atteindre la convergence: Rhat \<1.1.
Mais attention, cela nous indique uniquement si la chaine n'a pas
convergé. On ne peut pas être certain de la convergence même si le
critère est \<1.1.

-\> Valeur proche 1 : indique convergence probable. Acceptable si
inférieur à 1.1 Ici on a une valeur proche de 1. Rien à signaler
d'anormal pour la convergence.

#### Model selection: Compute WAIC criterion

```{r}
samples <- jags.samples(model3_fit$model,c("WAIC","deviance"), type = "mean",
n.iter = 6000,
n.burnin = 3000,
n.thin = 1)
samples$p_waic <- samples$WAIC #number of parameters
# Calculate the true AIC:
samples$waic <- samples$deviance + samples$p_waic
tmp <- sapply(samples, sum)
waic <- round(c(waic = tmp[["waic"]], p_waic = tmp[["p_waic"]],deviance = tmp[["deviance"]]),1)
waic$Modelname<-"model3"
waic$prior<-" mu.a~N(0,sd=10) // tau.a <- 1 / (sigma.a * sigma.a) //sigma.a~Unif(0,100)"


# Save the result:
waic<-as.data.frame(waic)
waic_save<-rbind(waic_save,waic)
                     
```

#### The results: look to posterior distributions

```{r}
# have a look to posterior distribution
hist(model1_fit$BUGSoutput$sims.matrix[,"a0"])
plot(density(model1_fit$BUGSoutput$sims.matrix[,"a0"]))
```

### Model 3_bis

Y\~ Poisson (T \* u) log (u) = a0 + Es + log(A) Prior: a0\~ N(0,sd=10)
Es\~ N(mu.es,tau.es) #tau.es = 1/variance=sigma.es² mu.es\~N(0,sd=10)
tau.es \<- 1 / (sigma.es \* sigma.es) sigma.es\~Unif(0,100)

```{r}
#Create dataframe of data for this model:
A<-as.numeric(data$Area)
nbsites<-length(unique(data$Site))
sites<-as.numeric(as.factor(data$Site))
mydata<-list(y=y,n=length(y),N=taillepop,A=A,nbsites=nbsites,sites=sites)
```

#### Write the model:

```{r}
model_3_bis<-function(){
  # likelihood
  for(i in 1:n){
    y[i] ~ dpois(lambda[i]) #likelihood
    lambda[i]<-N[i]*u[i]
    log(u[i]) <- a[sites[i]] + log(A[i]) # + a1*x[i]
  }
  for(j in 1:nbsites){
    a[j] ~ dnorm(mu.a,tau.a)
  } # For random effect of site
  # priors
  #a ~ dnorm(0,0.1) # sd=10
  #a1 ~ dnorm(0,0.1)
  mu.a ~ dnorm(0,0.1)
  tau.a <- 1 / (sigma.a * sigma.a)
  sigma.a ~ dunif(0,100)
}
```

#### Specify info to Jags

Initial values: We specify the initial values for 3 markov chains:

```{r}
init1 <- list(mu.a=1,sigma.a=0.5)
init2 <- list(mu.a=-3,sigma.a=1.5)
init3 <- list(mu.a=2,sigma.a=1)
init <- list(init1,init2,init3)
```

Parameters to monitor :

```{r}
params <- c("mu.a","sigma.a")
```

#### Fit the model with Jags

```{r}
model3_bis_fit <- jags(data = mydata,
                             inits = init,
                             parameters.to.save = params,
                             model.file = model_3_bis,
                             n.chains = 3,
                             n.iter = 10000,
                             n.burnin = 3000,
                             n.thin = 1)
```

```{r}
model3_bis_fit
```

#### Assess convergence

##### Qualitativement par des graphiques:

```{r}
traceplot(model3_bis_fit,mfrow=c(1,2),varname=c("mu.a","sigma.a"),ask=FALSE)
```
Le mixage semble ok mais pas parfait.
```{r}
autocorr.plot(as.mcmc(model3_bis_fit),ask=FALSE)
```
Avec les valeurs :n.iter = 6000, n.burnin = 3000, j'observe pas mal d'autocorrelationo pour sigma. Je décide d'augmenter le nombre d'itération à 10000. 

On observe une autocorrelation limitée, le nombre d'itérations spécifié semble convenir.
Mais reste un problème sur sigma on dirait.

##### Quantitativement:
###### N.eff : nb itérations ok pour limiter effet autocorrelation chaine
The effective sample size n.eff mesure la longueur de la chaine nécessaire en prenant en compte la corrélation entres celle ci. 
Le critère généralement choisit est de n.eff >100.
Ici on a bien nf >100. Donc le nombre d'itération est suffisant pour obtenir des estimateurs représentatif de la distribution postérieure.

```{r}
model3_bis_fit
```

###### Rhat: détecte si problème de convergence

Rhat mesure le ratio de la variabilité totale combinant multiple chaine
(entre les chaines et au sein des chaines) à la variabilité intra
chaine. Condition nécessaire pour atteindre la convergence: Rhat \<1.1.
Mais attention, cela nous indique uniquement si la chaine n'a pas
convergé. On ne peut pas être certain de la convergence même si le
critère est \<1.1.

-\> Valeur proche 1 : indique convergence probable. Acceptable si
inférieur à 1.1 Ici on a une valeur proche de 1. Rien à signaler
d'anormal pour la convergence.

#### Model selection: Compute WAIC criterion

```{r}
samples <- jags.samples(model3_bis_fit$model,c("WAIC","deviance"), type = "mean",
n.iter = 6000,
n.burnin = 3000,
n.thin = 1)
samples$p_waic <- samples$WAIC #number of parameters
# Calculate the true AIC:
samples$waic <- samples$deviance + samples$p_waic
tmp <- sapply(samples, sum)
waic <- round(c(waic = tmp[["waic"]], p_waic = tmp[["p_waic"]],deviance = tmp[["deviance"]]),1)
waic$Modelname<-"model3_bis"
waic$prior<-" mu.a~N(0,sd=10) // tau.a <- 1 / (sigma.a * sigma.a) //sigma.a~Unif(0,100)"


# Save the result:
waic<-as.data.frame(waic)
waic_save<-rbind(waic_save,waic)
                     
```

#### The results: look to posterior distributions

```{r}
# have a look to posterior distribution
hist(model1_fit$BUGSoutput$sims.matrix[,"a0"])
plot(density(model1_fit$BUGSoutput$sims.matrix[,"a0"]))
```

### Model 4

Y\~ Poisson (T \* u) log (u) = a0 + Es + a1*P Prior: a0\~ N(0,sd=10)
a1\~ N(0,sd=10) Es\~ N(mu.es,tau.es) #tau.es = 1/variance=sigma.es²
mu.es\~N(0,sd=10) tau.es \<- 1 / (sigma.es* sigma.es)
sigma.es\~Unif(0,100)

```{r}
#Create dataframe of data for this model:
A<-as.numeric(data$Area)
nbsites<-length(unique(data$Site))
sites<-as.numeric(as.factor(data$Site))
mydata<-list(y=y,x=x,n=length(y),N=taillepop,nbsites=nbsites,sites=sites)
```

#### Write the model:

```{r}
model_4<-function(){
  # likelihood
  for(i in 1:n){
    y[i] ~ dpois(lambda[i]) #likelihood
    lambda[i]<-N[i]*u[i]
    log(u[i]) <- a[sites[i]] + a1*x[i]  
  }
  for(j in 1:nbsites){
    a[j] ~ dnorm(mu.a,tau.a)
  } # For random effect of site
  # priors
  a1 ~ dnorm(0,0.1)
  mu.a ~ dnorm(0,0.1)
  tau.a <- 1 / (sigma.a * sigma.a)
  sigma.a ~ dunif(0,100)
}
```

#### Specify info to Jags

Initial values: We specify the initial values for 3 markov chains:

```{r}
init1 <- list(mu.a=1,sigma.a=0.5,a1=0)
init2 <- list(mu.a=-3,sigma.a=1.5,a1=1)
init3 <- list(mu.a=2,sigma.a=1,a1=0.5)
init <- list(init1,init2,init3)
```

Parameters to monitor :

```{r}
params <- c("mu.a","sigma.a","a1")
```

#### Fit the model with Jags

```{r}
model4_fit <- jags(data = mydata,
                             inits = init,
                             parameters.to.save = params,
                             model.file = model_4,
                             n.chains = 3,
                             n.iter = 10000,
                             n.burnin = 3000,
                             n.thin = 10)
```

```{r}
model4_fit
```

#### Assess convergence

##### Qualitativement par des graphiques:

```{r}
traceplot(model4_fit,mfrow=c(1,2),varname=c("mu.a","sigma.a","a1"),ask=FALSE)
```
Le mixage semble ok.
```{r}
autocorr.plot(as.mcmc(model4_fit),ask=FALSE)
```
Avec les valeurs :n.iter = 6000, n.burnin = 3000, j'observe pas mal d'autocorrelation. Je décide d'augmenter le nombre d'itération à 10000 et thinnning de 10.

Cependant, on observe une autocorrelation limitée, le nombre d'itérations spécifié semble convenir.

##### Quantitativement:
###### N.eff : nb itérations ok pour limiter effet autocorrelation chaine
The effective sample size n.eff mesure la longueur de la chaine nécessaire en prenant en compte la corrélation entres celle ci. 
Le critère généralement choisit est de n.eff >100.
Ici on a bien nf >100. Donc le nombre d'itération est suffisant pour obtenir des estimateurs représentatif de la distribution postérieure.

```{r}
model4_fit
```

###### Rhat: détecte si problème de convergence

Rhat mesure le ratio de la variabilité totale combinant multiple chaine
(entre les chaines et au sein des chaines) à la variabilité intra
chaine. Condition nécessaire pour atteindre la convergence: Rhat \<1.1.
Mais attention, cela nous indique uniquement si la chaine n'a pas
convergé. On ne peut pas être certain de la convergence même si le
critère est \<1.1.

-\> Valeur proche 1 : indique convergence probable. Acceptable si
inférieur à 1.1 Ici on a une valeur proche de 1. Rien à signaler
d'anormal pour la convergence.

#### Model selection: Compute WAIC criterion

```{r}
samples <- jags.samples(model4_fit$model,c("WAIC","deviance"), type = "mean",
n.iter = 6000,
n.burnin = 3000,
n.thin = 1)
samples$p_waic <- samples$WAIC #number of parameters
# Calculate the true AIC:
samples$waic <- samples$deviance + samples$p_waic
tmp <- sapply(samples, sum)
waic <- round(c(waic = tmp[["waic"]], p_waic = tmp[["p_waic"]],deviance = tmp[["deviance"]]),1)
waic$Modelname<-"model4"
waic$prior<-" mu.a~N(0,sd=10) // tau.a <- 1 / (sigma.a * sigma.a) //sigma.a~Unif(0,100)// a1~ N(0,sd=10) "


# Save the result:
waic<-as.data.frame(waic)
waic_save<-rbind(waic_save,waic)
                     
```

#### The results: look to posterior distributions

```{r}
# have a look to posterior distribution
hist(model1_fit$BUGSoutput$sims.matrix[,"a0"])
plot(density(model1_fit$BUGSoutput$sims.matrix[,"a0"]))
```

### Model 4_bis

Y\~ Poisson (T \* u) log (u) = a0 + Es + a1*P+ log(A) Prior: a0\~
N(0,sd=10) a1\~ N(0,sd=10) Es\~ N(mu.es,tau.es) #tau.es =
1/variance=sigma.es² mu.es\~N(0,sd=10) tau.es \<- 1 / (sigma.es*
sigma.es) sigma.es\~Unif(0,100)

```{r}
#Create dataframe of data for this model:
A<-as.numeric(data$Area)
nbsites<-length(unique(data$Site))
sites<-as.numeric(as.factor(data$Site))
mydata<-list(y=y,x=x,n=length(y),N=taillepop,A=A,nbsites=nbsites,sites=sites)
```

#### Write the model:

```{r}
model_4_bis<-function(){
  # likelihood
  for(i in 1:n){
    y[i] ~ dpois(lambda[i]) #likelihood
    lambda[i]<-N[i]*u[i]
    log(u[i]) <- a[sites[i]] + a1*x[i] + log(A[i]) 
  }
  for(j in 1:nbsites){
    a[j] ~ dnorm(mu.a,tau.a)
  } # For random effect of site
  # priors
  a1 ~ dnorm(0,0.1)
  mu.a ~ dnorm(0,0.1)
  tau.a <- 1 / (sigma.a * sigma.a)
  sigma.a ~ dunif(0,100)
}
```

#### Specify info to Jags

Initial values: We specify the initial values for 3 markov chains:

```{r}
init1 <- list(mu.a=1,sigma.a=0.5,a1=0)
init2 <- list(mu.a=-3,sigma.a=1.5,a1=1)
init3 <- list(mu.a=2,sigma.a=1,a1=0.5)
init <- list(init1,init2,init3)
```

Parameters to monitor :

```{r}
params <- c("mu.a","sigma.a","a1")
```

#### Fit the model with Jags

```{r}
model4_bis_fit <- jags(data = mydata,
                             inits = init,
                             parameters.to.save = params,
                             model.file = model_4_bis,
                             n.chains = 3,
                             n.iter = 10000,
                             n.burnin = 3000,
                             n.thin = 10)
```

```{r}
model4_bis_fit
```

#### Assess convergence

##### Qualitativement par des graphiques:

```{r}
traceplot(model4_bis_fit,mfrow=c(1,2),varname=c("mu.a","sigma.a","a1"),ask=FALSE)
```

Le mixage semble ok.
```{r}
autocorr.plot(as.mcmc(model4_bis_fit),ask=FALSE)
```

Avec les valeurs :n.iter = 6000, n.burnin = 3000, j'observe pas mal d'autocorrelation. Je décide d'augmenter le nombre d'itération à 10000 et thinnning de 10.

Cependant, on observe une autocorrelation limitée, le nombre d'itérations spécifié semble convenir.

##### Quantitativement:
###### N.eff : nb itérations ok pour limiter effet autocorrelation chaine
The effective sample size n.eff mesure la longueur de la chaine nécessaire en prenant en compte la corrélation entres celle ci. 
Le critère généralement choisit est de n.eff >100.
Ici on a bien nf >100. Donc le nombre d'itération est suffisant pour obtenir des estimateurs représentatif de la distribution postérieure.

```{r}
model4_bis_fit
```

###### Rhat: détecte si problème de convergence

Rhat mesure le ratio de la variabilité totale combinant multiple chaine
(entre les chaines et au sein des chaines) à la variabilité intra
chaine. Condition nécessaire pour atteindre la convergence: Rhat \<1.1.
Mais attention, cela nous indique uniquement si la chaine n'a pas
convergé. On ne peut pas être certain de la convergence même si le
critère est \<1.1.

-\> Valeur proche 1 : indique convergence probable. Acceptable si
inférieur à 1.1 Ici on a une valeur proche de 1. Rien à signaler
d'anormal pour la convergence.

#### Model selection: Compute WAIC criterion

```{r}
samples <- jags.samples(model4_bis_fit$model,c("WAIC","deviance"), type = "mean",
n.iter = 6000,
n.burnin = 3000,
n.thin = 1)
samples$p_waic <- samples$WAIC #number of parameters
# Calculate the true AIC:
samples$waic <- samples$deviance + samples$p_waic
tmp <- sapply(samples, sum)
waic <- round(c(waic = tmp[["waic"]], p_waic = tmp[["p_waic"]],deviance = tmp[["deviance"]]),1)
waic$Modelname<-"model4_bis"
waic$prior<-" mu.a~N(0,sd=10) // tau.a <- 1 / (sigma.a * sigma.a) //sigma.a~Unif(0,100)// a1~ N(0,sd=10) "


# Save the result:
waic<-as.data.frame(waic)
waic_save<-rbind(waic_save,waic)
                     
```

#### The results: look to posterior distributions

```{r}
# have a look to posterior distribution
hist(model1_fit$BUGSoutput$sims.matrix[,"a0"])
plot(density(model1_fit$BUGSoutput$sims.matrix[,"a0"]))
```

### Model 5_bis

Y\~ Poisson (T \* u) log (u) = a0 + Ey + a1*P+ log(A) Prior: a0\~
N(0,sd=10) a1\~ N(0,sd=10) Ey\~ N(mu.y,tau.y) #tau.es =
1/variance=sigma.ey² mu.y\~N(0,sd=10) tau.y \<- 1 / (sigma.y* sigma.y)
sigma.es\~Unif(0,100)

```{r}
#Create dataframe of data for this model:
A<-as.numeric(data$Area)
nbsites<-length(unique(data$Site))
sites<-as.numeric(data$Site)
yearID<-data %>% group_by(year)%>% mutate(year_id = cur_group_id())
yearID<-yearID$year_id
nbyear<-length(unique(data$year))
mydata<-list(y=y,x=x,n=length(y),N=taillepop,A=A,year=yearID,nbyear=nbyear)
```

#### Write the model:

```{r}
model_5_bis<-function(){
  # likelihood
  for(i in 1:n){
    y[i] ~ dpois(lambda[i]) #likelihood
    lambda[i]<-N[i]*u[i]
    log(u[i]) <-ab[year[i]] + a1*x[i] + log(A[i]) 
  }

  for(f in 1:nbyear){
    ab[f] ~ dnorm(mu.y,tau.y)
  } # For random effect of year
  # priors
  a1 ~ dnorm(0,0.1)
  mu.y ~ dnorm(0,0.1)
  tau.y <- 1 / (sigma.y * sigma.y)
  sigma.y ~ dunif(0,100)
}
```

#### Specify info to Jags

Initial values: We specify the initial values for 3 markov chains:

```{r}
init1 <- list(a1=0,mu.y=1,sigma.y=0.5)
init2 <- list(a1=1,mu.y=-3,sigma.y=1.5)
init3 <- list(a1=0.5,mu.y=-2,sigma.y=3)
init <- list(init1,init2,init3)
```

Parameters to monitor :

```{r}
params <- c("a1","mu.y","sigma.y")
```

#### Fit the model with Jags

```{r}
model5_bis_fit <- jags(data = mydata,
                             inits = init,
                             parameters.to.save = params,
                             model.file = model_5_bis,
                             n.chains = 3,
                             n.iter = 200000,
                             n.burnin = 5000,
                             n.thin = 100)
```

```{r}
model5_bis_fit
```

#### Assess convergence

##### Qualitativement par des graphiques:

```{r}
traceplot(model5_bis_fit,mfrow=c(1,2),varname=c("a1","mu.y","sigma.y"),ask=FALSE)

Le mixage semble ok.

autocorr.plot(as.mcmc(model5_bis_fit),ask=FALSE)
Avec les valeurs :n.iter = 6000, n.burnin = 3000, j'observe pas mal d'autocorrelation. Je décide d'augmenter le nombre d'itération à 10000 et thinnning de 10.

Cependant, on observe une autocorrelation limitée, le nombre d'itérations spécifié semble convenir.

##### Quantitativement:
###### N.eff : nb itérations ok pour limiter effet autocorrelation chaine
The effective sample size n.eff mesure la longueur de la chaine nécessaire en prenant en compte la corrélation entres celle ci. 
Le critère généralement choisit est de n.eff >100.
Ici on a bien nf >100. Donc le nombre d'itération est suffisant pour obtenir des estimateurs représentatif de la distribution postérieure.

model5_bis_fit
```

###### Rhat: détecte si problème de convergence

Rhat mesure le ratio de la variabilité totale combinant multiple chaine
(entre les chaines et au sein des chaines) à la variabilité intra
chaine. Condition nécessaire pour atteindre la convergence: Rhat \<1.1.
Mais attention, cela nous indique uniquement si la chaine n'a pas
convergé. On ne peut pas être certain de la convergence même si le
critère est \<1.1.

-\> Valeur proche 1 : indique convergence probable. Acceptable si
inférieur à 1.1 Ici on a une valeur proche de 1. Rien à signaler
d'anormal pour la convergence.

#### Model selection: Compute WAIC criterion

```{r}
samples <- jags.samples(model5_bis_fit$model,c("WAIC","deviance"), type = "mean",
n.iter = 100000,
n.burnin = 5000,
n.thin = 100)
samples$p_waic <- samples$WAIC #number of parameters
# Calculate the true AIC:
samples$waic <- samples$deviance + samples$p_waic
tmp <- sapply(samples, sum)
waic <- round(c(waic = tmp[["waic"]], p_waic = tmp[["p_waic"]],deviance = tmp[["deviance"]]),1)
waic$Modelname<-"model5_bis"
waic$prior<-" mu.a~N(0,sd=10) // tau.a <- 1 / (sigma.a * sigma.a) //sigma.a~Unif(0,100)// a1~ N(0,sd=10) mu.y~N(0,sd=10) // tau.y <- 1 / (sigma.y * sigma.y) //sigma.y~Unif(0,100)//"


# Save the result:
waic<-as.data.frame(waic)
#waic_save<-rbind(waic_save,waic)
                     
```

#### The results: look to posterior distributions

```{r}
# have a look to posterior distribution
hist(model1_fit$BUGSoutput$sims.matrix[,"a0"])
plot(density(model1_fit$BUGSoutput$sims.matrix[,"a0"]))
```

DO NOT CONVERGE WELL (random effect on year) \### Model 6_bis Y\~
Poisson (T \* u) log (u) = a0 + Es + Ey + a1*P+ log(A) Prior: a0\~
N(0,sd=10) a1\~ N(0,sd=10) Es\~ N(mu.es,tau.es) #tau.es =
1/variance=sigma.es² mu.es\~N(0,sd=10) tau.es \<- 1 / (sigma.es*
sigma.es) sigma.es\~Unif(0,100) Ey\~ N(mu.y,tau.y) #tau.es =
1/variance=sigma.ey² mu.y\~N(0,sd=10) tau.y \<- 1 / (sigma.y \* sigma.y)
sigma.es\~Unif(0,100)

```{r}
#Create dataframe of data for this model:
A<-as.numeric(data$Area)
nbsites<-length(unique(data$Site))
sites<-as.numeric(as.factor(data$Site))
yearID<-data %>% group_by(year)%>% mutate(year_id = cur_group_id())
yearID<-yearID$year_id
nbyear<-length(unique(data$year))
mydata<-list(y=y,x=x,n=length(y),N=taillepop,A=A,nbsites=nbsites,sites=sites,year=yearID,nbyear=nbyear)
```

#### Write the model:

```{r}
model_6_bis<-function(){
  # likelihood
  for(i in 1:n){
    y[i] ~ dpois(lambda[i]) #likelihood
    lambda[i]<-N[i]*u[i]
    log(u[i]) <- a[sites[i]] + ab[year[i]] + a1*x[i] + log(A[i]) 
  }
  for(j in 1:nbsites){
    a[j] ~ dnorm(mu.a,tau.a)
  } # For random effect of site
  for(f in 1:nbyear){
    ab[f] ~ dnorm(mu.y,tau.y)
  } # For random effect of site
  # priors
  a1 ~ dnorm(0,0.1)
  mu.a ~ dnorm(0,0.1)
  tau.a <- 1 / (sigma.a * sigma.a)
  sigma.a ~ dunif(0,100)
  
  mu.y ~ dnorm(0,0.1)
  tau.y <- 1 / (sigma.y * sigma.y)
  sigma.y ~ dunif(0,100)
}
```

#### Specify info to Jags

Initial values: We specify the initial values for 3 markov chains:

```{r}
init1 <- list(mu.a=-4,sigma.a=0.5,a1=0,mu.y=1,sigma.y=0.5)
init2 <- list(mu.a=-3,sigma.a=1.5,a1=1,mu.y=-3,sigma.y=1.5)
init3 <- list(mu.a=-1,sigma.a=1,a1=0.5,mu.y=-2,sigma.y=3)
init <- list(init1,init2,init3)
```

Parameters to monitor :

```{r}
params <- c("mu.a","sigma.a","a1","mu.y","sigma.y")
```

#### Fit the model with Jags

```{r}
model6_bis_fit <- jags(data = mydata,
                             inits = init,
                             parameters.to.save = params,
                             model.file = model_5_bis,
                             n.chains = 3,
                             n.iter = 200000,
                             n.burnin = 5000,
                             n.thin = 1000)
```

```{r}
model6_bis_fit
```

#### Assess convergence

##### Qualitativement par des graphiques:

```{r}
traceplot(model6_bis_fit,mfrow=c(1,2),varname=c("mu.a","sigma.a","a1","mu.y","sigma.y"),ask=FALSE)
plot(as.mcmc(model6_bis_fit))

Le mixage semble ok.

autocorr.plot(as.mcmc(model6_bis_fit),ask=FALSE)
Avec les valeurs :n.iter = 6000, n.burnin = 3000, j'observe pas mal d'autocorrelation. Je décide d'augmenter le nombre d'itération à 10000 et thinnning de 10.

Cependant, on observe une autocorrelation limitée, le nombre d'itérations spécifié semble convenir.

##### Quantitativement:
###### N.eff : nb itérations ok pour limiter effet autocorrelation chaine
The effective sample size n.eff mesure la longueur de la chaine nécessaire en prenant en compte la corrélation entres celle ci. 
Le critère généralement choisit est de n.eff >100.
Ici on a bien nf >100. Donc le nombre d'itération est suffisant pour obtenir des estimateurs représentatif de la distribution postérieure.

model5_bis_fit
```

###### Rhat: détecte si problème de convergence

Rhat mesure le ratio de la variabilité totale combinant multiple chaine
(entre les chaines et au sein des chaines) à la variabilité intra
chaine. Condition nécessaire pour atteindre la convergence: Rhat \<1.1.
Mais attention, cela nous indique uniquement si la chaine n'a pas
convergé. On ne peut pas être certain de la convergence même si le
critère est \<1.1.

-\> Valeur proche 1 : indique convergence probable. Acceptable si
inférieur à 1.1 Ici on a une valeur proche de 1. Rien à signaler
d'anormal pour la convergence.

#### Model selection: Compute WAIC criterion

```{r}
samples <- jags.samples(model5_bis_fit$model,c("WAIC","deviance"), type = "mean",
n.iter = 6000,
n.burnin = 3000,
n.thin = 1)
samples$p_waic <- samples$WAIC #number of parameters
# Calculate the true AIC:
samples$waic <- samples$deviance + samples$p_waic
tmp <- sapply(samples, sum)
waic <- round(c(waic = tmp[["waic"]], p_waic = tmp[["p_waic"]],deviance = tmp[["deviance"]]),1)
waic$Modelname<-"model5_bis"
waic$prior<-" mu.a~N(0,sd=10) // tau.a <- 1 / (sigma.a * sigma.a) //sigma.a~Unif(0,100)// a1~ N(0,sd=10) mu.y~N(0,sd=10) // tau.y <- 1 / (sigma.y * sigma.y) //sigma.y~Unif(0,100)//"


# Save the result:
waic<-as.data.frame(waic)
#waic_save<-rbind(waic_save,waic)
                     
```

#### The results: look to posterior distributions

```{r}
# have a look to posterior distribution
hist(model1_fit$BUGSoutput$sims.matrix[,"a0"])
plot(density(model1_fit$BUGSoutput$sims.matrix[,"a0"]))
```

DO NOT CONVERGE WELL (random effect on year and site) \## Part 2: more
graph and test for model validation of Model2_bis and model4_bis (same
as part assessing convergence for each model but with more beautiful
graph) \### Chaine mixing et model validation:: Comparons Model 2_bis
Modèle 4_bis

```{r}
plot(as.mcmc(model2_bis_fit))
plot(as.mcmc(model4_bis_fit))
```

Les chaines semblent well mixted et stable pour le modèle 2bis_fit.

### Test autocorrelation (déjà fait plus haut juste autre méthode)

```{r}
autocorr.diag(as.mcmc(model2_bis_fit))
autocorr.diag(as.mcmc(model4_bis_fit))
```

Seems ok.

### Test résidus pour model2_bis

One very important model validation procedure is to examine a plot of
residuals against predicted or fitted values (the residual plot).
Ideally, residual plots should show a random scatter of points without
outliers. That is, there should be no patterns in the residuals.
Patterns suggest inappropriate linear predictor (or scale) and/or
inappropriate residual distribution/link function.

```{r}
mydata<-list(y=y,x=x,n=length(y),N=120,A=A)
coefs <- model2_bis_fit$BUGSoutput$sims.matrix[,1:2]
Xmat <- model.matrix(~x, data=mydata)
#expected values on a log scale
eta<-coefs %*% t(Xmat)
#expected value on response scale
lambda <- exp(eta)
#Expected value and variance are both equal to lambda
expY <- varY <- lambda
#sweep across rows and then divide by lambda
Resid <- -1*sweep(expY,2,dat$y,'-')/sqrt(varY)
#plot residuals vs expected values
plot(apply(Resid,2,mean)~apply(eta,2,mean))
```

On a l'air de voir des patterns vers la gauche ? ce qui n'est pas idéal.

## Part 2: Model Selection: WAIC criterion

```{r}
waic_save
model_DIC<-c(model1_fit$BUGSoutput$DIC,model1_bis_fit$BUGSoutput$DIC,model2_fit$BUGSoutput$DIC,model2_bis_fit$BUGSoutput$DIC,model3_fit$BUGSoutput$DIC,model3_bis_fit$BUGSoutput$DIC,model4_fit$BUGSoutput$DIC,model4_bis_fit$BUGSoutput$DIC)
CRITERIA_modelselection<-cbind(waic_save,model_DIC)
CRITERIA_modelselection$Modelname <- factor(CRITERIA_modelselection$Modelname, levels = CRITERIA_modelselection$Modelname[order(CRITERIA_modelselection$waic)])
ggplot(CRITERIA_modelselection,aes(x=Modelname,y=waic)) + theme_bw() + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle=70, hjust=1))


```

Model 2_bis semble être le mieux fit au data selon les critères. Modèle
4_bis est assez proche également.

## Part 1/2: look for overdipersion:

Poisson regression: hypothèse de base est que variance=mean. Donc
dispersion = 1.

Explore potential for overdispersion in data: Source:
<https://www.flutterbys.com.au/stats/tut/tut10.6b.html>

```{r}
boxplot(data$shells, horizontal=TRUE)
rug(jitter(data$shells), side=1)
hist(data$shell)
```

Il semble y avoir beaucoup de 0 dans les données = potentiel
overdispersion.
Les rugs appliqués au bar plot semblent indiqué une série de clumping assez clair.
Overdispersion est likely to be an issue.

Explore zero inflation:

```{r}
#proportion of 0's in the data
dat.tab<-table(data$shell==0)
dat.tab/sum(dat.tab)

#Proportion of 0's expected from a Poisson distribution
mu <- mean(data$shells)
cnts <- rpois(1000, mu)
dat.tab <- table(cnts == 0)
dat.tab/sum(dat.tab)
```

The value under TRUE is the proportion of zero value in the data. The
proportion of the value is the data do not correspond to the low
proportion expected for a poisson distribution.

```{r}
# Fit model frequentist approach
M1 <- glm(shells ~prev,
          family = 'poisson',
          data = data)

summary(M1)
# Check for over/underdispersion in the model
E2 <- resid(M1, type = "pearson")
N  <- nrow(data)
p  <- length(coef(M1))   
sum(E2^2) / (N - p)
# Look like our model produce overdispersion.
# Let's try negative binomial approach
library(MASS)
M2 <- glm.nb(shells ~prev,
             data = data)

summary(M2)
# Dispersion statistic
E2 <- resid(M2, type = "pearson")
N  <- nrow(data)
p  <- length(coef(M2)) + 1  # '+1' is for variance parameter in NB
sum(E2^2) / (N - p)
# more overdispersion with binomial negative
library(pscl)
M3 <- zeroinfl(shells ~prev| ## Predictor for the Poisson process
                 prev, ## Predictor for the Bernoulli process;
               dist = 'poisson',
               data = data)

summary(M3)
# Dispersion statistic
E2 <- resid(M3, type = "pearson")
N  <- nrow(data)
p  <- length(coef(M3))  
sum(E2^2) / (N - p)

M4 <- zeroinfl(shells ~prev |
                 prev,
               dist = 'negbin',
               data = data)
summary(M4)
#Dispersion Statistic
E2 <- resid(M4, type = "pearson")
N  <- nrow(data)
p  <- length(coef(M4)) + 1 # '+1' is due to theta
sum(E2^2) / (N - p)
library(lmtest)
lrtest(M3, M4)
```

To do: - Faire graphiques pour Result

## Result of model 2bis visualization

```{r}



```
